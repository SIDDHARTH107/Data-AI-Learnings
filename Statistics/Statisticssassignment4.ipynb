{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The Probability Mass Function (PMF) is used to describe the probability distribution of a discrete random variable. It assigns a probability to each possible value that the random variable can take.\n",
        "\n",
        "For example, consider the roll of a fair six-sided die. The PMF for this scenario would be a list of probabilities corresponding to each possible value of the die roll:\n",
        "\n",
        "P(X=1) = 1/6\n",
        "P(X=2) = 1/6\n",
        "P(X=3) = 1/6\n",
        "P(X=4) = 1/6\n",
        "P(X=5) = 1/6\n",
        "P(X=6) = 1/6"
      ],
      "metadata": {
        "id": "Y9ll7TsPAJYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the other hand, the Probability Density Function (PDF) is used to describe the probability distribution of a continuous random variable. It gives the probability density at each possible value of the random variable, rather than assigning probabilities to specific values.\n",
        "\n",
        "For example, consider the height of people in a population. The PDF for this scenario would give the probability density at each possible height value. However, since height is a continuous variable, the PDF is represented as a continuous function rather than a list of probabilities."
      ],
      "metadata": {
        "id": "kFFDUje1AOH6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Cumulative Density Function (CDF) is a function that describes the probability that a random variable takes on a value less than or equal to a given value.\n",
        "\n",
        "For a discrete random variable, the CDF can be computed by summing the probabilities of all values less than or equal to the given value. For a continuous random variable, the CDF can be computed by integrating the probability density function (PDF) from negative infinity up to the given value.\n",
        "\n",
        "For example, let's consider the roll of a fair six-sided die. The CDF for this scenario would be:\n",
        "\n",
        "P(X <= 1) = 1/6\n",
        "P(X <= 2) = 2/6\n",
        "P(X <= 3) = 3/6\n",
        "P(X <= 4) = 4/6\n",
        "P(X <= 5) = 5/6\n",
        "P(X <= 6) = 6/6 = 1\n",
        "The CDF is used to calculate the probability that a random variable falls within a particular range, or to find the probability of a specific value or range of values. It is also useful for comparing different probability distributions, as it provides a standardized way of measuring the relative probabilities of different values or ranges."
      ],
      "metadata": {
        "id": "dvLT9OCAAd_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The normal distribution is commonly used as a model in situations where the data follows a bell-shaped curve. Some examples of situations where the normal distribution might be used as a model include:\n",
        "\n",
        "Height or weight measurements of a population\n",
        "IQ scores or test scores of a group of people\n",
        "The amount of time it takes to complete a task\n",
        "The daily returns of a financial asset\n",
        "The normal distribution has two parameters: the mean (μ) and the standard deviation (σ). The mean determines the center of the distribution, while the standard deviation determines the spread of the distribution. Specifically:\n",
        "\n",
        "The mean determines the location of the peak of the distribution.\n",
        "The standard deviation determines the width of the distribution, with larger values indicating a wider spread of data and smaller values indicating a narrower spread.\n",
        "The normal distribution is a symmetric distribution, meaning that the mean, median, and mode are all equal and located at the center of the distribution. The standard deviation also plays an important role in the normal distribution as it determines the probability of observing data within a certain range around the mean, using the empirical rule (68-95-99.7 rule).\n"
      ],
      "metadata": {
        "id": "Q7JBK0QgBRtZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The normal distribution is one of the most important probability distributions in statistics and is commonly used in many fields due to its numerous applications. Here are some reasons why normal distribution is important:\n",
        "\n",
        "Many natural phenomena exhibit a normal distribution, making it a useful model for scientific studies and data analysis.\n",
        "\n",
        "Normal distribution has a bell-shaped curve, making it easy to interpret and analyze data. It can be used to understand and analyze the characteristics of data such as the mean, standard deviation, and probability.\n",
        "\n",
        "The Central Limit Theorem states that if we have a large enough sample size, the sample means will follow a normal distribution regardless of the underlying distribution of the population. This theorem makes the normal distribution a key concept in statistical inference.\n",
        "\n",
        "The normal distribution is often used in hypothesis testing, such as in determining confidence intervals or performing significance tests.\n",
        "\n",
        "Some examples of real-life applications of the normal distribution include:\n",
        "\n",
        "Heights and weights of a population\n",
        "IQ scores and test scores of students\n",
        "Daily stock returns of a company\n",
        "Measurement errors in scientific experiments\n",
        "Blood pressure readings of a population\n",
        "Monthly rainfall measurements in a particular region\n",
        "In each of these examples, the normal distribution can be used to describe the data and make predictions about future measurements."
      ],
      "metadata": {
        "id": "Hnw2UM87B6L6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Bernoulli distribution is a discrete probability distribution that models a single trial with only two possible outcomes: success with probability p and failure with probability 1-p. It is named after the Swiss mathematician Jacob Bernoulli, who introduced it in his work on the theory of probability.\n",
        "\n",
        "An example of a Bernoulli distribution is flipping a coin, where the success is getting heads and the failure is getting tails. Another example is a person buying a product or not, where the success is buying the product and the failure is not buying the product.\n",
        "\n",
        "The main difference between Bernoulli distribution and Binomial distribution is that the Bernoulli distribution is used to model a single trial with two possible outcomes, while the Binomial distribution is used to model the number of successes in a fixed number of independent Bernoulli trials. In other words, Bernoulli distribution is a special case of the Binomial distribution with n=1."
      ],
      "metadata": {
        "id": "yl55SVvyCUzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find the probability that a randomly selected observation will be greater than 60 in a normally distributed dataset with a mean of 50 and a standard deviation of 10, we can use the standard normal distribution.\n",
        "\n",
        "First, we need to standardize the value of 60 using the formula:\n",
        "z = (x - mu) / sigma\n",
        "where z is the standardized value, x is the value of interest, mu is the mean of the dataset, and sigma is the standard deviation of the dataset.\n",
        "\n",
        "Plugging in the values, we get:\n",
        "z = (60 - 50) / 10\n",
        "z = 1\n",
        "\n",
        "We can then use a standard normal distribution table or calculator to find the probability of z being greater than 1. In this case, the probability is approximately 0.1587 or 15.87%.\n",
        "\n",
        "Alternatively, we can use the cumulative distribution function (CDF) of the standard normal distribution to find the probability. Using a calculator or software, we can find that the probability of z being less than or equal to 1 is 0.8413. Therefore, the probability of z being greater than 1 is 1 - 0.8413 = 0.1587 or 15.87%.\n",
        "\n",
        "So the probability that a randomly selected observation from the dataset will be greater than 60 is approximately 0.1587 or 15.87%."
      ],
      "metadata": {
        "id": "zeZELPFdC1Ql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uniform distribution is a probability distribution where all values in the distribution have equal probability of being selected. This means that the probability of an event occurring between any two points in the distribution is proportional to the length of the interval between those points.\n",
        "\n",
        "For example, consider a scenario where a fair dice is rolled. The possible outcomes are 1, 2, 3, 4, 5, and 6. Since each outcome has an equal probability of occurring, we can say that the distribution of outcomes is uniform. In this case, the probability of rolling any particular number is 1/6, and the probability of rolling any number between two intervals is proportional to the length of the interval.\n",
        "\n",
        "Another example of a uniform distribution is the selection of a random number from a range of values, such as selecting a number between 1 and 100. In this case, each number has an equal probability of being selected, and the distribution of outcomes is uniform."
      ],
      "metadata": {
        "id": "NZtaM8dpDM7C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The z-score is a statistical measure that shows how many standard deviations an observation or data point is above or below the mean of the dataset. It is calculated by subtracting the mean of the dataset from the data point, and then dividing that difference by the standard deviation of the dataset. The formula for calculating the z-score of a data point x in a dataset with mean μ and standard deviation σ is:\n",
        "\n",
        "z = (x - μ) / σ\n",
        "\n",
        "The z-score is important because it allows us to compare observations or data points from different datasets, which may have different scales or units. By standardizing the values to the z-score scale, we can compare and analyze the data more easily. For example, we can use the z-score to determine the probability of an observation occurring within a certain range of values, regardless of the original dataset's mean and standard deviation. The z-score is also useful in hypothesis testing and determining statistical significance."
      ],
      "metadata": {
        "id": "PGQTCJotDeOB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Central Limit Theorem (CLT) is a statistical theory that states that the means of a large number of independent and identically distributed (i.i.d.) random variables will be approximately normally distributed, regardless of the underlying distribution of the variables themselves.\n",
        "\n",
        "The significance of the Central Limit Theorem is that it provides a powerful tool for statistical inference in a wide range of situations. For example, if we have a sample of data that is not normally distributed, but we want to estimate the population mean or test a hypothesis about the mean, we can use the CLT to assume that the sampling distribution of the mean will be approximately normal, and use this to calculate probabilities and make inferences. The CLT also allows us to use the normal distribution as an approximation for many other distributions, which simplifies calculations and makes statistical analyses more tractable."
      ],
      "metadata": {
        "id": "-F5_txMWDsSo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Central Limit Theorem (CLT) has the following assumptions:\n",
        "\n",
        "The sample size must be large enough: The sample size should be at least 30 or the population should have a normal distribution.\n",
        "\n",
        "Independence of observations: Each observation in the sample must be independent of each other.\n",
        "\n",
        "Finite variance: The variance of the population should be finite.\n",
        "\n",
        "Random Sampling: The sample is drawn randomly from the population.\n",
        "\n",
        "These assumptions help to ensure that the sampling distribution of the mean approaches a normal distribution, which is the main idea behind the Central Limit Theorem."
      ],
      "metadata": {
        "id": "0v7-htakD7N7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qIUjW0KHAKOv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}