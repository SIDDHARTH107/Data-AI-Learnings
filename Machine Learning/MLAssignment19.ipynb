{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is the mathematical formula for a linear SVM?\n",
        "\n",
        "The mathematical formula for a linear SVM is:\n",
        "\n",
        "Code snippet\n",
        "w * x + b = 0\n",
        "Use code with caution. Learn more\n",
        "where w is the weight vector, x is the input vector, and b is the bias term. This formula represents a hyperplane that separates the two classes of data. The goal of SVM is to find the hyperplane that has the maximum margin between the two classes.\n",
        "\n",
        "Q2. What is the objective function of a linear SVM?\n",
        "\n",
        "The objective function of a linear SVM is to maximize the margin between the two classes of data. This is formulated as the following optimization problem:\n",
        "\n",
        "Code snippet\n",
        "maximize: ||w||^2\n",
        "subject to: yi(w * xi + b) >= 1 for all i\n",
        "Use code with caution. Learn more\n",
        "where yi is the label of the i-th data point, and ||w||^2 is the square of the norm of the weight vector w. The constraint ensures that all of the data points are on the correct side of the hyperplane.\n",
        "\n",
        "Q3. What is the kernel trick in SVM?\n",
        "\n",
        "The kernel trick is a technique that allows SVM to be used for non-linear classification problems. The kernel trick works by transforming the data into a higher-dimensional space where the data is linearly separable. The most common kernel used in SVM is the radial basis function (RBF) kernel.\n",
        "\n",
        "The RBF kernel is defined as:\n",
        "\n",
        "Code snippet\n",
        "K(x, x') = exp(-||x - x'||^2 / 2σ^2)\n",
        "Use code with caution. Learn more\n",
        "where x and x' are two data points, and σ is a parameter that controls the width of the kernel. The RBF kernel measures the similarity between two data points in the higher-dimensional space.\n",
        "\n",
        "Q4. What is the role of support vectors in SVM?\n",
        "\n",
        "The support vectors are the data points that are closest to the hyperplane. These data points are used to define the hyperplane and to calculate the margin. The number of support vectors is typically much smaller than the total number of data points.\n",
        "\n",
        "For example, consider the following two-dimensional data set with two classes:\n",
        "\n",
        "Code snippet\n",
        "class 1: (1, 1), (2, 2), (3, 3)\n",
        "class 2: (-1, -1), (-2, -2), (-3, -3)\n",
        "Use code with caution. Learn more\n",
        "The hyperplane that separates these two classes is:\n",
        "\n",
        "Code snippet\n",
        "w * x + b = 0\n",
        "Use code with caution. Learn more\n",
        "The support vectors are the data points that are closest to the hyperplane. In this case, the support vectors are (1, 1) and (-1, -1).\n",
        "\n",
        "Q5. Illustrate with examples and graphs of Hyperplane, Marginal plane, Soft margin and Hard margin in SVM?\n",
        "\n",
        "A hyperplane is a line or a plane that separates two classes of data. The margin is the distance between the hyperplane and the closest data points. A hard margin SVM is an SVM that uses a hard margin, which means that all of the data points must be on the correct side of the hyperplane. A soft margin SVM is an SVM that uses a soft margin, which means that some of the data points can be on the wrong side of the hyperplane, but they must be within a certain distance of the hyperplane.\n",
        "\n",
        "The following figure illustrates a hyperplane, marginal plane, soft margin, and hard margin in SVM:\n",
        "hyperplane, marginal plane, soft margin, and hard margin in SVMOpens in a new window\n",
        "Towards AI\n",
        "hyperplane, marginal plane, soft margin, and hard margin in SVM\n",
        "\n",
        "The hyperplane is the blue line. The marginal plane is the shaded area between the hyperplane and the closest data points. The soft margin SVM is represented by the dotted line. The hard margin SVM is represented by the solid line."
      ],
      "metadata": {
        "id": "NcyTyoK-zUpC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "po_mDPhfzxIf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}