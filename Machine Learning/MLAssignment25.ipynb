{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. How does bagging reduce overfitting in decision trees?\n",
        "\n",
        "Bagging reduces overfitting in decision trees by training multiple decision trees on different bootstrap samples of the original data. This helps to reduce the variance of the decision trees, which makes them less likely to overfit the training data.\n",
        "\n",
        "Q2. What are the advantages and disadvantages of using different types of base learners in bagging?\n",
        "\n",
        "The advantages of using different types of base learners in bagging include:\n",
        "\n",
        "It can help to reduce the variance of the ensemble, which can improve the accuracy of the ensemble.\n",
        "It can help to improve the robustness of the ensemble to noise and outliers.\n",
        "The disadvantages of using different types of base learners in bagging include:\n",
        "\n",
        "It can make the ensemble more complex and difficult to interpret.\n",
        "It can make the ensemble less efficient to train.\n",
        "Q3. How does the choice of base learner affect the bias-variance tradeoff in bagging?\n",
        "\n",
        "The choice of base learner affects the bias-variance tradeoff in bagging in the following way:\n",
        "\n",
        "If a base learner has low bias, then it will tend to underfit the training data. This will reduce the variance of the ensemble, but it will also increase the bias of the ensemble.\n",
        "If a base learner has high bias, then it will tend to overfit the training data. This will increase the variance of the ensemble, but it will also reduce the bias of the ensemble.\n",
        "Q4. Can bagging be used for both classification and regression tasks? How does it differ in each case?\n",
        "\n",
        "Yes, bagging can be used for both classification and regression tasks. In classification tasks, bagging is used to train multiple decision trees on different bootstrap samples of the original data. The predictions of the decision trees are then combined to produce a final prediction. In regression tasks, bagging is used to train multiple linear regression models on different bootstrap samples of the original data. The predictions of the linear regression models are then combined to produce a final prediction.\n",
        "\n",
        "Q5. What is the role of ensemble size in bagging? How many models should be included in the ensemble?\n",
        "\n",
        "The ensemble size is the number of models that are included in the ensemble. The ensemble size affects the accuracy and robustness of the ensemble. A larger ensemble size will tend to be more accurate, but it will also be more computationally expensive to train. A smaller ensemble size will be less accurate, but it will be less computationally expensive to train.\n",
        "\n",
        "The number of models that should be included in the ensemble depends on the specific application. In general, a larger ensemble size is better for accuracy, but a smaller ensemble size is better for computational efficiency.\n",
        "\n",
        "Q6. Can you provide an example of a real-world application of bagging in machine learning?\n",
        "\n",
        "Bagging is used in a variety of real-world applications, including:\n",
        "\n",
        "Spam filtering\n",
        "Fraud detection\n",
        "Medical diagnosis\n",
        "Financial forecasting\n",
        "Natural language processing\n",
        "One example of a real-world application of bagging is spam filtering. In spam filtering, bagging is used to train multiple decision trees on different bootstrap samples of the original data. The predictions of the decision trees are then combined to produce a final prediction. This helps to reduce the false positive rate of spam filtering, which is the rate at which non-spam emails are classified"
      ],
      "metadata": {
        "id": "NcyTyoK-zUpC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "po_mDPhfzxIf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}